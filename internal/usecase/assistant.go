package usecase

import (
	"context"
	"fmt"
	"os"
	"strings"

	"github.com/truong-nautilus/smart-home-ai/internal/domain"
)

// KeyboardListener interface cho vi·ªác l·∫Øng nghe ph√≠m b·∫•m (hold/release)
type KeyboardListener interface {
	WaitForSpacePress() error   // Ch·ªù Space ƒë∆∞·ª£c nh·∫•n
	WaitForSpaceRelease() error // Ch·ªù Space ƒë∆∞·ª£c nh·∫£
}

// AssistantUseCase orchestrates the AI assistant workflow
type AssistantUseCase struct {
	mediaCapturer     domain.MediaCapturer
	speechRecognizer  domain.SpeechRecognizer
	aiAssistant       domain.AIAssistant
	speechSynthesizer domain.SpeechSynthesizer
	keyboardListener  KeyboardListener
	logger            Logger
}

// Logger interface for logging
type Logger interface {
	Info(msg string)
	Error(msg string, err error)
}

// NewAssistantUseCase creates a new assistant use case
func NewAssistantUseCase(
	mediaCapturer domain.MediaCapturer,
	speechRecognizer domain.SpeechRecognizer,
	aiAssistant domain.AIAssistant,
	speechSynthesizer domain.SpeechSynthesizer,
	keyboardListener KeyboardListener,
	logger Logger,
) *AssistantUseCase {
	return &AssistantUseCase{
		mediaCapturer:     mediaCapturer,
		speechRecognizer:  speechRecognizer,
		aiAssistant:       aiAssistant,
		speechSynthesizer: speechSynthesizer,
		keyboardListener:  keyboardListener,
		logger:            logger,
	}
}

// Execute runs the complete AI assistant workflow (hold-space voice mode)
func (uc *AssistantUseCase) Execute(ctx context.Context) error {
	const (
		audioFile = "audio.wav"
		replyFile = "reply.mp3"
	)

	// Cleanup temp files on exit
	defer uc.cleanup(audioFile, replyFile)

	// Step 1: Ch·ªù ng∆∞·ªùi d√πng nh·∫•n Space
	if err := uc.keyboardListener.WaitForSpacePress(); err != nil {
		uc.logger.Error("‚ùå L·ªói khi ƒë·ªçc ph√≠m", err)
		return fmt.Errorf("kh√¥ng th·ªÉ ƒë·ªçc ph√≠m b·∫•m: %w", err)
	}

	// Step 2: B·∫Øt ƒë·∫ßu ghi √¢m trong background
	cancelRecording, err := uc.mediaCapturer.StartRecording(ctx, audioFile)
	if err != nil {
		uc.logger.Error("‚ùå L·ªói b·∫Øt ƒë·∫ßu ghi √¢m", err)
		return fmt.Errorf("kh√¥ng th·ªÉ b·∫Øt ƒë·∫ßu ghi √¢m: %w", err)
	}
	defer cancelRecording() // ƒê·∫£m b·∫£o cancel n·∫øu c√≥ l·ªói

	// Step 3: Ch·ªù ng∆∞·ªùi d√πng nh·∫£ Space
	if err := uc.keyboardListener.WaitForSpaceRelease(); err != nil {
		uc.logger.Error("‚ùå L·ªói khi ƒë·ªçc ph√≠m", err)
		return fmt.Errorf("kh√¥ng th·ªÉ ƒë·ªçc ph√≠m nh·∫£: %w", err)
	}

	// Step 4: D·ª´ng ghi √¢m
	if err := uc.mediaCapturer.StopRecording(); err != nil {
		uc.logger.Error("‚ùå L·ªói d·ª´ng ghi √¢m", err)
		return fmt.Errorf("kh√¥ng th·ªÉ d·ª´ng ghi √¢m: %w", err)
	}
	uc.logger.Info("‚úÖ ƒê√£ ghi √¢m xong")

	// Step 5: Transcribe audio
	uc.logger.Info("üß† ƒêang chuy·ªÉn gi·ªçng n√≥i th√†nh vƒÉn b·∫£n...")
	transcription, err := uc.speechRecognizer.Transcribe(ctx, audioFile)
	if err != nil {
		uc.logger.Error("‚ùå L·ªói transcribe", err)
		return fmt.Errorf("kh√¥ng th·ªÉ chuy·ªÉn gi·ªçng n√≥i: %w", err)
	}

	// Log ƒë·ªÉ debug
	text := transcription.Text
	uc.logger.Info(fmt.Sprintf("üîç Whisper output: \"%s\"", text))

	// Ki·ªÉm tra xem c√≥ n·ªôi dung th·ª±c s·ª± kh√¥ng (b·ªè qua blank audio, music, noise)
	if text == "" ||
		strings.Contains(text, "[BLANK_AUDIO]") ||
		strings.Contains(text, "[Music]") ||
		strings.Contains(text, "[Silence]") ||
		strings.Contains(text, "(electronic beeping)") ||
		len(strings.TrimSpace(text)) < 3 {
		uc.logger.Info("‚ö†Ô∏è Kh√¥ng ph√°t hi·ªán gi·ªçng n√≥i r√µ r√†ng, ti·∫øp t·ª•c l·∫Øng nghe...")
		return nil // Kh√¥ng l·ªói, ch·ªâ l√† kh√¥ng c√≥ gi·ªçng n√≥i
	}

	uc.logger.Info(fmt.Sprintf("üìù C√¢u h·ªèi: \"%s\"", text))

	// Step 6: Analyze with AI (kh√¥ng c·∫ßn h√¨nh ·∫£nh)
	uc.logger.Info("ü§ñ ƒêang x·ª≠ l√Ω c√¢u h·ªèi...")
	response, err := uc.aiAssistant.AnalyzeMultimodal(ctx, text, "")
	if err != nil {
		return fmt.Errorf("kh√¥ng th·ªÉ nh·∫≠n ph·∫£n h·ªìi t·ª´ AI: %w", err)
	}
	uc.logger.Info(fmt.Sprintf("üí¨ Tr·∫£ l·ªùi: \"%s\"", response.Text))

	// Step 7: Synthesize speech
	uc.logger.Info("üîä ƒêang t·ªïng h·ª£p gi·ªçng n√≥i (s·ª≠ d·ª•ng 'say' tr√™n macOS)...")
	if _, err := uc.speechSynthesizer.Synthesize(ctx, response.Text, replyFile); err != nil {
		return fmt.Errorf("kh√¥ng th·ªÉ t·ªïng h·ª£p gi·ªçng n√≥i: %w", err)
	}
	uc.logger.Info("‚úÖ T·ªïng h·ª£p gi·ªçng n√≥i th√†nh c√¥ng")

	// Step 8: Play audio
	uc.logger.Info("üîà ƒêang ph√°t √¢m thanh ph·∫£n h·ªìi...")
	if err := uc.mediaCapturer.PlayAudio(ctx, replyFile); err != nil {
		return fmt.Errorf("kh√¥ng th·ªÉ ph√°t √¢m thanh: %w", err)
	}

	uc.logger.Info("‚úÖ Ho√†n th√†nh!")
	return nil
}

func (uc *AssistantUseCase) cleanup(files ...string) {
	for _, file := range files {
		if _, err := os.Stat(file); err == nil {
			os.Remove(file)
		}
	}
}
