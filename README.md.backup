# Trá»£ LÃ½ AI Giá»ng NÃ³i (Local)

Trá»£ lÃ½ AI voice-only cháº¡y hoÃ n toÃ n local trÃªn macOS, sá»­ dá»¥ng:
- **Whisper.cpp** (small model) cho nháº­n dáº¡ng giá»ng nÃ³i tiáº¿ng Viá»‡t
- **Ollama** (gemma2:2b) cho xá»­ lÃ½ AI
- **Edge TTS** (Microsoft Neural Voices) cho giá»ng nÃ³i tá»± nhiÃªn

## ğŸ¯ Chá»©c NÄƒng

1. **Nháº¥n SPACE** + Enter Ä‘á»ƒ báº¯t Ä‘áº§u ghi Ã¢m (cháº¿ Ä‘á»™ push-to-talk)
2. **Ghi Ã¢m 10 giÃ¢y** tá»« microphone tÃ­ch há»£p
3. **Chuyá»ƒn Ä‘á»•i giá»ng nÃ³i** thÃ nh vÄƒn báº£n (tiáº¿ng Viá»‡t) báº±ng Whisper.cpp
4. **PhÃ¢n tÃ­ch** cÃ¢u há»i báº±ng Ollama (gemma2:2b)
5. **Tá»•ng há»£p** pháº£n há»“i thÃ nh giá»ng nÃ³i tá»± nhiÃªn báº±ng Edge TTS
6. **PhÃ¡t** Ã¢m thanh pháº£n há»“i

## Stack CÃ´ng Nghá»‡ (100% Local)

- **NgÃ´n ngá»¯**: Go 1.22+
- **Microphone**: FFmpeg vá»›i AVFoundation
- **Speech-to-Text**: whisper.cpp (ggml-small.bin model, 465MB) vá»›i language hint `-l vi`
- **AI Assistant**: Ollama (gemma2:2b, 1.6GB)
- **Text-to-Speech**: Edge TTS (Microsoft Neural Voices: vi-VN-NamMinhNeural/HoaiMyNeural)

## YÃªu Cáº§u Há»‡ Thá»‘ng

- macOS (Apple Silicon hoáº·c Intel)
- Go 1.22+
- FFmpeg vá»›i há»— trá»£ AVFoundation
- Ollama CLI
- whisper.cpp binary (Ä‘Ã£ build vá»›i cmake)
- Edge TTS (Python package)



## CÃ i Ä‘áº·t

### 1. CÃ i Ä‘áº·t Homebrew (náº¿u chÆ°a cÃ³)### 1. Install Homebrew (if not already installed)

### 1. CÃ i Ä‘áº·t Go

```bash```bash

```bash

brew install go/bin/bash -c "$(curl -fsSL https://raw.githubusercontent.com/Homebrew/install/HEAD/install.sh)"/bin/bash -c "$(curl -fsSL https://raw.githubusercontent.com/Homebrew/install/HEAD/install.sh)"

```

``````

### 2. CÃ i Ä‘áº·t FFmpeg



```bash

brew install ffmpeg### 2. CÃ i Ä‘áº·t ffmpeg vÃ  ffplay### 2. Install ffmpeg and ffplay

```

```bash```bash

### 3. CÃ i Ä‘áº·t Ollama

brew install ffmpegbrew install ffmpeg

```bash

# CÃ i Ä‘áº·t Ollama CLI``````

brew install ollama



# Khá»Ÿi Ä‘á»™ng Ollama service

ollama serve &### 3. CÃ i Ä‘áº·t Go 1.22+ (náº¿u chÆ°a cÃ³)### 3. Install Go 1.22+ (if not already installed)



# Pull model phi-3-mini (hoáº·c model nháº¹ khÃ¡c)```bash```bash

ollama pull phi-3-mini

```brew install gobrew install go



CÃ¡c model nháº¹ Ä‘Æ°á»£c Ä‘á» xuáº¥t:``````

- `phi-3-mini` (3.8B parameters) - cÃ¢n báº±ng tá»‘c Ä‘á»™ vÃ  cháº¥t lÆ°á»£ng

- `tinyllama` (1.1B parameters) - ráº¥t nháº¹, phÃ¹ há»£p mÃ¡y yáº¿u

- `gemma:2b` (2B parameters) - nhá» gá»n, hiá»‡u suáº¥t tá»‘t

### 4. Láº¥y OpenAI API Key### 4. Get an OpenAI API Key

### 4. Build whisper.cpp

- Truy cáº­p https://platform.openai.com/api-keys- Visit https://platform.openai.com/api-keys

```bash

# Clone repository- Táº¡o API key má»›i- Create a new API key

git clone https://github.com/ggerganov/whisper.cpp.git

cd whisper.cpp- Thiáº¿t láº­p biáº¿n mÃ´i trÆ°á»ng:- Set it as an environment variable:



# Build

make

```bash```bash

# Download model nhá» (base hoáº·c tiny)

bash ./models/download-ggml-model.sh baseexport OPENAI_API_KEY="sk-your-api-key-here"export OPENAI_API_KEY="sk-your-api-key-here"

# Hoáº·c model nhá» hÆ¡n:

# bash ./models/download-ggml-model.sh tiny``````



# LÆ°u Ä‘Æ°á»ng dáº«n binary vÃ  model

# Binary: ./main

# Model: ./models/ggml-base.bin**Máº¹o:** ThÃªm lá»‡nh export vÃ o `~/.zshrc` Ä‘á»ƒ lÆ°u vÄ©nh viá»…n:**Tip:** Add the export command to your `~/.zshrc` to persist it:

```

```bash```bash

### 5. Clone vÃ  build project

echo 'export OPENAI_API_KEY="sk-your-api-key-here"' >> ~/.zshrcecho 'export OPENAI_API_KEY="sk-your-api-key-here"' >> ~/.zshrc

```bash

# Clone repositorysource ~/.zshrcsource ~/.zshrc

git clone <repository-url>

cd smart-home-ai``````



# Táº£i dependencies

go mod download

Hoáº·c táº¡o file `.env`:## ğŸš€ Setup

# Build

go build -o smart-home-ai cmd/assistant/main.go```bash

```

echo 'OPENAI_API_KEY=sk-your-api-key-here' > .env1. **Clone or navigate to the project directory:**

## Cáº¥u hÃ¬nh

``````bash

Táº¡o file `.env` trong thÆ° má»¥c gá»‘c cá»§a project:

cd /Users/phamthetruong/github/smart-home-ai

```env

# Whisper.cpp configuration## ğŸš€ CÃ i Äáº·t```

WHISPER_CPP_BIN=/path/to/whisper.cpp/main

WHISPER_CPP_MODEL=/path/to/whisper.cpp/models/ggml-base.bin



# Ollama configuration1. **Di chuyá»ƒn Ä‘áº¿n thÆ° má»¥c dá»± Ã¡n:**2. **Download dependencies:**

OLLAMA_MODEL=phi-3-mini

```bash```bash

# MacTTS configuration (optional)

MACTTS_VOICE=Alexcd /Users/phamthetruong/github/smart-home-aigo mod tidy

```

``````

**CÃ¡c giá»ng nÃ³i macOS kháº£ dá»¥ng:**

- `Alex` (Má»¹, nam)

- `Samantha` (Má»¹, ná»¯)

- `Daniel` (Anh, nam)2. **Táº£i cÃ¡c dependency:**## â–¶ï¸ Run

- `Victoria` (Anh, ná»¯)

- Xem danh sÃ¡ch Ä‘áº§y Ä‘á»§: `say -v ?````bash



## Cháº¡y á»©ng dá»¥nggo mod tidy**Note:** The project now uses Clean Architecture. See [ARCHITECTURE.md](ARCHITECTURE.md) for details.



```bash```

# Cháº¡y trá»±c tiáº¿p

./smart-home-ai```bash



# Hoáº·c dÃ¹ng go run## â–¶ï¸ Cháº¡y á»¨ng Dá»¥ng# Run directly

go run cmd/assistant/main.go

```go run cmd/assistant/main.go



## Luá»“ng hoáº¡t Ä‘á»™ng**LÆ°u Ã½:** Dá»± Ã¡n sá»­ dá»¥ng Clean Architecture. Xem [KY_THUAT.md](KY_THUAT.md) Ä‘á»ƒ biáº¿t chi tiáº¿t.



1. **Chá»¥p áº£nh tá»« camera** - FFmpeg capture má»™t frame tá»« camera tÃ­ch há»£p# Or build binary

2. **Ghi Ã¢m cÃ¢u há»i** - FFmpeg ghi Ã¢m 5 giÃ¢y tá»« microphone

3. **Chuyá»ƒn giá»ng nÃ³i thÃ nh text** - whisper.cpp transcribe file audio```bashgo build -o smart-home-ai cmd/assistant/main.go

4. **PhÃ¢n tÃ­ch Ä‘a phÆ°Æ¡ng thá»©c** - Ollama xá»­ lÃ½ text + áº£nh

5. **PhÃ¡t giá»ng nÃ³i pháº£n há»“i** - macOS `say` Ä‘á»c cÃ¢u tráº£ lá»i# Cháº¡y trá»±c tiáº¿p./smart-home-ai



## Cáº¥u trÃºc thÆ° má»¥cgo run cmd/assistant/main.go```



```

smart-home-ai/

â”œâ”€â”€ cmd/# Hoáº·c build file thá»±c thi### Expected Output:

â”‚   â””â”€â”€ assistant/

â”‚       â””â”€â”€ main.go              # Entry pointgo build -o tro-ly-thong-minh cmd/assistant/main.go```

â”œâ”€â”€ internal/

â”‚   â”œâ”€â”€ domain/./tro-ly-thong-minh[15:04:05] ğŸ¥ Capturing image from FaceTime HD camera...

â”‚   â”‚   â”œâ”€â”€ entity.go            # Domain entities

â”‚   â”‚   â””â”€â”€ repository.go        # Repository interfaces (ports)```[15:04:06] âœ… Image captured successfully

â”‚   â”œâ”€â”€ usecase/

â”‚   â”‚   â””â”€â”€ assistant.go         # Business logic orchestration[15:04:06] ğŸ¤ Recording audio from microphone (5 seconds)...

â”‚   â””â”€â”€ infrastructure/

â”‚       â”œâ”€â”€ media/### Káº¿t Quáº£ Mong Äá»£i:[15:04:11] âœ… Audio recorded successfully

â”‚       â”‚   â””â”€â”€ ffmpeg.go        # FFmpeg adapter

â”‚       â”œâ”€â”€ whispercpp/```[15:04:11] ğŸ§  Transcribing speech with Whisper API...

â”‚       â”‚   â””â”€â”€ recognizer.go    # Whisper.cpp adapter

â”‚       â”œâ”€â”€ ollama/[15:04:05] ğŸ¥ Äang báº¯t áº£nh tá»« camera FaceTime HD...[15:04:12] ğŸ“ Transcription: "What do you see in front of me?"

â”‚       â”‚   â””â”€â”€ client.go        # Ollama adapter

â”‚       â””â”€â”€ mactts/[15:04:06] âœ… ÄÃ£ báº¯t áº£nh thÃ nh cÃ´ng[15:04:12] ğŸ¤– GPT-4o-mini reasoning on text + image...

â”‚           â””â”€â”€ synthesizer.go   # MacTTS adapter

â”œâ”€â”€ pkg/[15:04:06] ğŸ¤ Äang thu Ã¢m tá»« microphone (5 giÃ¢y)...[15:04:14] ğŸ’¬ GPT Response: "I can see you're sitting at a desk with a laptop..."

â”‚   â””â”€â”€ logger/

â”‚       â””â”€â”€ console.go           # Console logger[15:04:11] âœ… ÄÃ£ thu Ã¢m thÃ nh cÃ´ng[15:04:14] ğŸ”Š Converting response to speech with TTS...

â”œâ”€â”€ go.mod

â”œâ”€â”€ go.sum[15:04:11] ğŸ§  Äang chuyá»ƒn giá»ng nÃ³i thÃ nh vÄƒn báº£n vá»›i Whisper API...[15:04:16] âœ… Speech generated successfully

â”œâ”€â”€ .env                         # Configuration (táº¡o má»›i)

â””â”€â”€ README.md[15:04:12] ğŸ“ VÄƒn báº£n: "Báº¡n tháº¥y gÃ¬ trÆ°á»›c máº·t tÃ´i?"[15:04:16] ğŸ”ˆ Playing audio response...

```

[15:04:12] ğŸ¤– GPT-4o-mini Ä‘ang phÃ¢n tÃ­ch vÄƒn báº£n + hÃ¬nh áº£nh...[15:04:20] âœ… Done!

## Troubleshooting

[15:04:14] ğŸ’¬ Pháº£n há»“i GPT: "TÃ´i tháº¥y báº¡n Ä‘ang ngá»“i á»Ÿ bÃ n lÃ m viá»‡c vá»›i laptop..."```

### Lá»—i: "ffmpeg: No such file or directory"

[15:04:14] ğŸ”Š Äang chuyá»ƒn pháº£n há»“i thÃ nh giá»ng nÃ³i vá»›i TTS...

```bash

# Kiá»ƒm tra ffmpeg Ä‘Ã£ cÃ i Ä‘áº·t chÆ°a[15:04:16] âœ… ÄÃ£ táº¡o giá»ng nÃ³i thÃ nh cÃ´ng## ğŸ” Permissions

which ffmpeg

[15:04:16] ğŸ”ˆ Äang phÃ¡t Ã¢m thanh pháº£n há»“i...

# CÃ i Ä‘áº·t náº¿u chÆ°a cÃ³

brew install ffmpeg[15:04:20] âœ… HoÃ n thÃ nh!On first run, macOS will ask for permissions:

```

```- **Camera access** - Required to capture images

### Lá»—i: "ollama: command not found"

- **Microphone access** - Required to record audio

```bash

# CÃ i Ä‘áº·t Ollama## ğŸ” Quyá»n Truy Cáº­p

brew install ollama

Click "Allow" when prompted.

# Khá»Ÿi Ä‘á»™ng service

ollama serve &Láº§n cháº¡y Ä‘áº§u tiÃªn, macOS sáº½ yÃªu cáº§u quyá»n:



# Pull model- **Truy cáº­p Camera** - Cáº§n thiáº¿t Ä‘á»ƒ báº¯t áº£nh## ğŸ› ï¸ Troubleshooting

ollama pull phi-3-mini

```- **Truy cáº­p Microphone** - Cáº§n thiáº¿t Ä‘á»ƒ thu Ã¢m



### Lá»—i: "whisper.cpp: khÃ´ng tÃ¬m tháº¥y binary"### Camera/Microphone Not Found



Kiá»ƒm tra láº¡i Ä‘Æ°á»ng dáº«n trong file `.env`:Nháº¥p "Cho phÃ©p" khi Ä‘Æ°á»£c nháº¯c.If you get an error about device not found, list available devices:



```env```bash

WHISPER_CPP_BIN=/Users/yourusername/whisper.cpp/main

WHISPER_CPP_MODEL=/Users/yourusername/whisper.cpp/models/ggml-base.bin## ğŸ› ï¸ Kháº¯c Phá»¥c Sá»± Cá»‘ffmpeg -f avfoundation -list_devices true -i ""

```

```

### Lá»—i: "avfoundation: Cannot find device"

### KhÃ´ng TÃ¬m Tháº¥y Camera/Microphone

Cáº¥p quyá»n cho Terminal/iTerm2 truy cáº­p camera vÃ  microphone trong **System Preferences â†’ Privacy & Security**.

Náº¿u gáº·p lá»—i vá» thiáº¿t bá»‹ khÃ´ng tÃ¬m tháº¥y, liá»‡t kÃª cÃ¡c thiáº¿t bá»‹ cÃ³ sáºµn:This will show something like:

## License

```bash```

MIT

ffmpeg -f avfoundation -list_devices true -i ""[0] FaceTime HD Camera

## Contributing

```[1] External Camera

Pull requests are welcome!

[:0] Built-in Microphone

Káº¿t quáº£ sáº½ hiá»ƒn thá»‹:[:1] External Microphone

``````

[0] FaceTime HD Camera

[1] External CameraUpdate `main.go` if needed:

[:0] Built-in Microphone- For video: change `"-i", "0"` to your camera index

[:1] External Microphone- For audio: change `"-i", ":0"` to your microphone index

```

### API Key Not Set

Cáº­p nháº­t `internal/infrastructure/media/ffmpeg.go` náº¿u cáº§n:If you see `OPENAI_API_KEY environment variable not set`:

- Vá»›i video: thay Ä‘á»•i `"-i", "0"` thÃ nh chá»‰ sá»‘ camera cá»§a báº¡n```bash

- Vá»›i audio: thay Ä‘á»•i `"-i", ":0"` thÃ nh chá»‰ sá»‘ microphone cá»§a báº¡nexport OPENAI_API_KEY="your-key-here"

```

### ChÆ°a Thiáº¿t Láº­p API Key

Náº¿u tháº¥y `ChÆ°a thiáº¿t láº­p biáº¿n mÃ´i trÆ°á»ng OPENAI_API_KEY`:### FFmpeg Not Installed

```bashIf you get `executable file not found`:

export OPENAI_API_KEY="your-key-here"```bash

```brew install ffmpeg

```

Hoáº·c táº¡o file `.env`:

```bash## ğŸ“¦ Dependencies

echo 'OPENAI_API_KEY=sk-your-key-here' > .env

```- **Go 1.22+**

- **github.com/sashabaranov/go-openai** v1.20.4 - OpenAI Go client

### ChÆ°a CÃ i FFmpeg- **ffmpeg** - Audio/video capture and playback

Náº¿u gáº·p lá»—i `executable file not found`:- **OpenAI APIs:**

```bash  - Whisper (speech-to-text)

brew install ffmpeg  - GPT-4o-mini (multimodal reasoning)

```  - TTS-1 (text-to-speech)



## ğŸ“¦ CÃ¡c Dependency## ğŸ§¹ Cleanup



- **Go 1.22+**Temporary files (`frame.jpg`, `audio.wav`, `reply.mp3`) are automatically cleaned up after each run.

- **github.com/sashabaranov/go-openai** v1.20.4 - OpenAI Go client

- **github.com/joho/godotenv** v1.5.1 - Táº£i biáº¿n mÃ´i trÆ°á»ng tá»« .env## ğŸ“ Notes

- **ffmpeg** - Báº¯t vÃ  phÃ¡t Ã¢m thanh/video

- **OpenAI APIs:**- The assistant records **5 seconds** of audio by default (configurable in `main.go`)

  - Whisper (chuyá»ƒn giá»ng nÃ³i thÃ nh vÄƒn báº£n)- Camera captures a **640x480** frame (configurable)

  - GPT-4o-mini (phÃ¢n tÃ­ch Ä‘a phÆ°Æ¡ng thá»©c)- Audio is recorded in **mono at 16kHz** (optimal for Whisper)

  - TTS-1 (chuyá»ƒn vÄƒn báº£n thÃ nh giá»ng nÃ³i)- TTS uses the **Alloy voice** (configurable to: alloy, echo, fable, onyx, nova, shimmer)



## ğŸ“ Cáº¥u TrÃºc Dá»± Ãn## ğŸ¨ Customization



```Edit `main.go` to customize:

smart-home-ai/- `audioDuration` - Change recording length

â”œâ”€â”€ cmd/assistant/              # Äiá»ƒm vÃ o á»©ng dá»¥ng- `Voice` - Change TTS voice in `textToSpeech()`

â”‚   â””â”€â”€ main.go                 # Dependency injection- `video_size` - Change camera resolution in `captureImage()`

â”œâ”€â”€ internal/- `Model` - Switch between GPT models

â”‚   â”œâ”€â”€ domain/                 # Logic nghiá»‡p vá»¥ cá»‘t lÃµi

â”‚   â”‚   â”œâ”€â”€ entity.go           # CÃ¡c entity nghiá»‡p vá»¥## ğŸ“„ License

â”‚   â”‚   â””â”€â”€ repository.go       # Interface (ports)

â”‚   â”œâ”€â”€ usecase/                # Logic á»©ng dá»¥ngMIT

â”‚   â”‚   â””â”€â”€ assistant.go        # Äiá»u phá»‘i quy trÃ¬nh
â”‚   â””â”€â”€ infrastructure/         # Adapter dá»‹ch vá»¥ bÃªn ngoÃ i
â”‚       â”œâ”€â”€ openai/             # OpenAI API client
â”‚       â”‚   â””â”€â”€ client.go
â”‚       â””â”€â”€ media/              # FFmpeg wrapper
â”‚           â””â”€â”€ ffmpeg.go
â”œâ”€â”€ pkg/logger/                 # Tiá»‡n Ã­ch chia sáº»
â”‚   â””â”€â”€ console.go
â”œâ”€â”€ .env                        # Biáº¿n mÃ´i trÆ°á»ng
â”œâ”€â”€ .gitignore                  # Quy táº¯c ignore Git
â”œâ”€â”€ go.mod                      # Äá»‹nh nghÄ©a Go module
â””â”€â”€ CÃ¡c file tÃ i liá»‡u
```

## ğŸ§¹ Dá»n Dáº¹p

CÃ¡c file táº¡m (`hinh-anh.jpg`, `am-thanh.wav`, `tra-loi.mp3`) Ä‘Æ°á»£c tá»± Ä‘á»™ng dá»n dáº¹p sau má»—i láº§n cháº¡y.

## ğŸ“ Ghi ChÃº

- Trá»£ lÃ½ thu Ã¢m **5 giÃ¢y** máº·c Ä‘á»‹nh (cÃ³ thá»ƒ cáº¥u hÃ¬nh trong `internal/usecase/assistant.go`)
- Camera báº¯t áº£nh **640x480** (cÃ³ thá»ƒ cáº¥u hÃ¬nh)
- Ã‚m thanh thu á»Ÿ **mono vá»›i táº§n sá»‘ 16kHz** (tá»‘i Æ°u cho Whisper)
- TTS sá»­ dá»¥ng giá»ng **Alloy** (cÃ³ thá»ƒ chá»n: alloy, echo, fable, onyx, nova, shimmer)

## ğŸ¨ TÃ¹y Chá»‰nh

Chá»‰nh sá»­a cÃ¡c file Ä‘á»ƒ tÃ¹y chá»‰nh:
- `internal/usecase/assistant.go` - Thay Ä‘á»•i thá»i lÆ°á»£ng thu Ã¢m (`thoiLuongThuAm`)
- `internal/infrastructure/openai/client.go` - Thay Ä‘á»•i giá»ng TTS trong phÆ°Æ¡ng thá»©c `TongHop()`
- `internal/infrastructure/media/ffmpeg.go` - Thay Ä‘á»•i Ä‘á»™ phÃ¢n giáº£i camera trong `BatAnh()`
- Chuyá»ƒn Ä‘á»•i giá»¯a cÃ¡c model GPT khÃ¡c nhau

## ğŸ—ï¸ Kiáº¿n TrÃºc

Dá»± Ã¡n sá»­ dá»¥ng **Clean Architecture** vá»›i:
- **Domain Layer**: Entity vÃ  interface cá»‘t lÃµi
- **Use Case Layer**: Logic Ä‘iá»u phá»‘i nghiá»‡p vá»¥
- **Infrastructure Layer**: Triá»ƒn khai adapter
- **Delivery Layer**: Äiá»ƒm vÃ o vÃ  dependency injection

Xem [KY_THUAT.md](KY_THUAT.md) Ä‘á»ƒ biáº¿t chi tiáº¿t vá» kiáº¿n trÃºc.

## ğŸ“š TÃ i Liá»‡u Bá»• Sung

- **[HUONG_DAN_NHANH.md](HUONG_DAN_NHANH.md)** - HÆ°á»›ng dáº«n nhanh 2 phÃºt
- **[KY_THUAT.md](KY_THUAT.md)** - TÃ¬m hiá»ƒu sÃ¢u vá» thiáº¿t káº¿
- **[SO_DO_KY_THUAT.md](SO_DO_KY_THUAT.md)** - HÆ°á»›ng dáº«n trá»±c quan
- **[TOM_TAT_TAI_CAU_TRUC.md](TOM_TAT_TAI_CAU_TRUC.md)** - Nhá»¯ng gÃ¬ Ä‘Ã£ thay Ä‘á»•i
- **[README_EN.md](README_EN.md)** - English version

## ğŸ“„ Giáº¥y PhÃ©p

MIT

---

**ChÃºc báº¡n láº­p trÃ¬nh vui váº»!** ğŸ¯
